{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and interrogating data\n",
    "After making a telescope, pointing it at something interesting and recording data, we want to analyse it to get some science out of it. The first step to that in modern astronomy is to read that data into a computer. Even within `python`, there are a number of ways of doing that. Often data is written in a bespoke manner, so it's worth knowing a few tricks for reading in data We'll start with the basics, and then concentrate on using the `pandas` package to read and plot a real astronomical data set.\n",
    "\n",
    "Perhaps the simplest data set is are numbers stored in a text file. In this directory, you will find a text file called `simple_data1.txt`. We'll first read the data in the file using `numpy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.genfromtxt('simple_data1.txt')\n",
    "\n",
    "print(\"Data type = \", type(data))\n",
    "print(\"Data shape = \", data.shape)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `loadtxt` function has returned a 2-dimensional `array` based on the data in the text file. We have printed this out, and found the shape to be three by three, using the `.shape` attribute of the data `array`. We can access elements of the array just like a 1D array, but now we need two indexes to specify a location (kind of like an $x,y$ coordinate). Both axis are zero indexed, so we access the first element of the array like this `data[0,0]`.\n",
    "\n",
    "If we think of the horizontal direction as `x`, and the vertical as `y`, the indexing works like this:\n",
    "\n",
    "$$\n",
    "\\begin{array}{ccc} \n",
    "[[y_0,x_0 & y_0,x_1 & y_0,x_2] \\\\ \n",
    "[y_1,x_0 & y_1,x_1 & y_1,x_2] \\\\ \n",
    "[y_2,x_0 & y_2,x_1 & y_2,x_2]] \\\\ \n",
    "\\end{array} \n",
    "$$\n",
    "\n",
    "<font color='red'>TODO if we are doing stuff on 2D arrays, we can say we'll be doing more on them in the future</font>\n",
    "\n",
    "In this simple case we were able to easily read in the data. What happens if we have column headings in our text file however? We can pass set the `names` arguement to `True`, which will read the first line as column headers. We can then access specific columns by name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt('simple_data2.txt',names=True)\n",
    "print(data)\n",
    "print(data['Column2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we add in some text to our data? Try running the box below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt('simple_data3.txt',names=True)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without help from us, `genfromtxt` is trying to read all columns in a floats. `nan` means \"not a number\", and is a kind of place-holder for a computer when something has gone wrong. Although we can fiddle with `genfromtxt` to read in this data correctly, we're going to use a different package, called `pandas`. Let's give it a whirl:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "##A csv file is a \"comma separated value\" text file. This text file\n",
    "##is separated by spaces, so we have to tell pandas to use a space\n",
    "##to separate values, using the 'delimiter'\n",
    "df = pd.read_csv('simple_data3.txt',delimiter=' ')\n",
    "\n",
    "##print out some interesting things\n",
    "##in the below, I want to space out some of the outputs.\n",
    "##The '\\n' is called a 'newline' escape sequence, and\n",
    "##has the same effect as pressing the enter button on your\n",
    "##keyboard when typing text\n",
    "print('What are we working with now?')\n",
    "print(type(df),'\\n')\n",
    "\n",
    "print('The data frame looks like this:')\n",
    "print(df,'\\n')\n",
    "\n",
    "print('Check what columns were titled automagically: ')\n",
    "print(df.columns,'\\n')\n",
    "\n",
    "print('Try accessing a single column by name: ')\n",
    "print(df['Column1'],'\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So `pandas` has read the data into a Class called a data frame (`df`), which has many nice features to easily access, manipulate, and visualise the data. Let's check out some of the functionality using some real data.\n",
    "\n",
    "## GAMA data\n",
    "The Galaxy And Mass Assembly (GAMA) survey is an optical survey, which collected spectra and redshifts of more than 100,00 galaxies (check out a paper from [Driver et al 2011](https://ui.adsabs.harvard.edu/abs/2011MNRAS.413..971D/abstract) for a more detailed explanation. I downloaded data for 1000 of those galaxies from [here](https://vizier.u-strasbg.fr/viz-bin/VizieR-3?-source=J/MNRAS/413/971/gamacore&-out.max=50&-out.form=HTML%20Table&-out.add=_r&-out.add=_RAJ,_DEJ&-sort=_r&-oc.form=sexa), and saved it as `GAMA_data.tsv`. Let's load it into a data frame and see what we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "##This particular data set came separated by the colon character, so select that\n",
    "df = pd.read_csv('GAMA_data.tsv',delimiter=';')\n",
    "\n",
    "print('Check what columns were titled automagically: ')\n",
    "print(df.columns,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, let's look where on the sky our sample of galaxies lie by plotting their RA/Dec coordinates. A dataframe Class has a plotting attribute, so let's use that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(x='RAJ2000', y='DEJ2000',kind='scatter')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so we have a large concentration of galaxies at a Declination of just above 0.5 degrees, with a few outliers. Let's say we didn't care about those galaxies away from the main group. We can get rid of them using array indexing like we would with a `numpy` array. The syntax below says \"only include rows where the value of `RAJ2000` is less than 181.0 degrees\", and we assign the cropped data frame the name `cropped_df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_df = df[df.RAJ2000 < 181.0]\n",
    "cropped_df.plot(x='RAJ2000', y='DEJ2000',kind='scatter')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neat thing about this, is that we've cropped the data based on the `RAJ2000` value, but cropped the entire data frame object, meaning all columns have been cropped in the same way.\n",
    "\n",
    "Ok, let's check out some other properties of the data. The column called `zh` stands for Heliocentric redshift. Let's look at the range of values using a histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##The bins argument sets the number of bins to bine the data into\n",
    "cropped_df['zh'].hist(bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right, well redshift is a measure of distance, and can't be negative, so what's going on here? It turns out if a redshift was 'embargoed' in this data, it was give a value of -2.0. Let's do something about this.\n",
    "\n",
    "## <font color=blue>Exercise 2.1<font>\n",
    "Plot a histogram of the 'zh' column, excluding any negative values. Use the box below.\n",
    "<font color=red>Optional extension:<font> set the axis labels for your plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another neat trick is to group the data by a certain variable using the `group` function. There is a column called `G`, where the objects were grouped by spectrum. First of all, we can check for all the unique values in G: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(df['G'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for these 1000 galaxies, we see `G` is either blank, 12, or 15. We can plot any colum, grouped by it's `G` value, using this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['zh'].hist(by=df['G'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=blue>Exercise 2.2<font>\n",
    "Plot histograms of the `rPmag` column, grouped by the column `G`.See if you can infer a correlation between magnitude and group. <font color=red>Optional extension:<font> explicitly set the bins to be the same for all the histograms, to make it easier to compare the grouped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLEAM data\n",
    "The GaLactic and Extragalactic All-sky Murchison Widefield Array (GLEAM) survey catalogue (see [Hurley-Walker et al. 2017](https://academic.oup.com/mnras/article/464/1/1146/2280761) is a collection of low radio-frequency sources in the southern hemisphere. A typical data format that you will encounter in astronomy is the FITS standard (brief Wikipedia overview [here](https://en.wikipedia.org/wiki/FITS#:~:text=Flexible%20Image%20Transport%20System%20(FITS,digital%20file%20format%20in%20astronomy.) )), but we can read FITS files into `pandas` by using the `astropy` package. `astropy` is an extremely useful package that we will use later in the course. I have cropped the GLEAM catalogue (which should have > 300,000 sources) to make it smaller and easier to download. To look at the GLEAM data, first of all, let's read it into a data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##The GLEAM FITS file is formatted as a table, so use\n",
    "##the astropy.table functionality\n",
    "from astropy.table import Table\n",
    "\n",
    "##Read the table in to return an astropy Table object\n",
    "dat = Table.read('GLEAM_cat_cropped.fits')\n",
    "\n",
    "##The Table Class has a handy attribute to form a data frame\n",
    "df = dat.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! We've loaded our FITS table file into a pandas data frame, so now let's see what's inside:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This reduced version of the catalogue includes the source position (RA, Dec), the flux density (brightness) of the source as a function of frequency, and the size of the source on the sky. The size of the source is described by fitting a two dimensional elliptical Gaussian to the radio image, yielding a size measured by the semi-major (labelled $a$) and semi-minor ($b$) axes (image credit By M. W. Toews - Own work, CC0, [link](https://commons.wikimedia.org/w/index.php?curid=56897423)):\n",
    "\n",
    "<img src=\"Ellipse_semi-major_and_minor_axes.svg\" width=\"400\">\n",
    "\n",
    "Here is an explanation of the columns:\n",
    "\n",
    "| Column Name | Meaning\n",
    "| :-: | :-: |\n",
    "| GLEAM | Source name |\n",
    "| RAJ2000 | Right Ascension (deg) |\n",
    "| DEJ2000 | Declination (deg) |\n",
    "| Fintwide | Flux density integrated over frequencies (Jy,centred at 200MHz) |\n",
    "| awide | Elliptical-gaussian Major axis (centred at 200MHz) |\n",
    "| bwide | Elliptical-gaussian Minor axis (centred at 200MHz) |\n",
    "| pawide | Elliptical-gaussian position angle |\n",
    "| Fint076 | Flux density at 076 MHz |\n",
    "| Fint084 | Flux density at 084 MHz |\n",
    "| Fint092 | Flux density at 092 MHz |\n",
    "| Fint099 | Flux density at 099 MHz |\n",
    "| Fint107 | Flux density at 107 MHz |\n",
    "| Fint115 | Flux density at 115 MHz |\n",
    "| Fint122 | Flux density at 122 MHz |\n",
    "| Fint130 | Flux density at 130 MHz |\n",
    "| Fint143 | Flux density at 143 MHz |\n",
    "| Fint151 | Flux density at 151 MHz |\n",
    "| Fint158 | Flux density at 158 MHz |\n",
    "| Fint166 | Flux density at 166 MHz |\n",
    "| Fint174 | Flux density at 174 MHz |\n",
    "| Fint181 | Flux density at 181 MHz |\n",
    "| Fint189 | Flux density at 189 MHz |\n",
    "| Fint197 | Flux density at 197 MHz |\n",
    "| Fint204 | Flux density at 204 MHz |\n",
    "| Fint212 | Flux density at 212 MHz |\n",
    "| Fint220 | Flux density at 220 MHz |\n",
    "| Fint227 | Flux density at 227 MHz |\n",
    "| alpha | Fitted spectral index |\n",
    "\n",
    "Ok, let's have a look at some of the data!\n",
    "\n",
    "## <font color='blue'>Exercise 2.3 <font>\n",
    "Plot the `RAJ2000` vs the `DEJ2000` columns on a scatter plot to see where on the sky our sources lie. Also plot a histogram of the fitted spectral index values. You should see a strip of sky where there are no sources - can you guess what that area is? (Or you could read the GLEAM paper to find out)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a reminder from the last notebook, the spectral index is defined via this equation:\n",
    "\n",
    "$$ S = S_0\\nu^\\alpha $$\n",
    "\n",
    "where $S$ is the flux density (how bright it appears, measured in Jy), $S_0$ is a reference flux density, $\\nu$ is the frequency, and $\\alpha$ is the spectral index of the source. Next, we'll see how to make a new column based on the data to see if sources with a positive spectral index are special"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create a new column, called 'positive_alpha', where that column\n",
    "##is True when alpha > 0, and False otherwise. Acheive this by\n",
    "##creating an array of booleans using the greater than > operator\n",
    "df['positive_alpha'] = df['alpha'] > 0\n",
    "\n",
    "##Let's see if the positive spectral index sources are brighter/dimmer\n",
    "##than negative spectral indexes, by plotting histograms grouped by\n",
    "##our new 'positive_alpha' column\n",
    "df['Fintwide'].hist(by=df['positive_alpha'],bins=np.linspace(0,10,20))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first glance the two flux distributions look very similar, although clearly there are far more negative SI than positive SI. However, they are hard to see on this plot. We can change the scale of the y-axis to a log scale to make things clearer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "axs = df['Fintwide'].hist(by=df['positive_alpha'],bins=np.linspace(0,10,20))\n",
    "\n",
    "##When we made the histogram plot, it returned a list of Axes\n",
    "##objects. We can use the attribute set_yscale to change to a\n",
    "##log scale to make thing clearer\n",
    "axs[0].set_yscale('log')\n",
    "axs[1].set_yscale('log')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The flux distributions still look similar at first glance, but splitting data up by certain measurements and checking the differences can tell us about the physical processes happening in the radio galaxies we are looking at. In this case, the emission mechanism is something called *synchrotron* radiation, which gives rise to a spectral index of around -0.8. Further processes in the galaxies themselves are changing the spectral index to something more positive.\n",
    "\n",
    "## <font color='blue'>Exercise 2.4<font>\n",
    "Make a new column called `above_mean`, where you test whether `alpha` is above the mean of `alpha` by using the `np.mean` function. Then plot histograms of `Fintwide` grouped by `above_mean`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SED of a radio source\n",
    "The spectral energy distribution (SED) of a radio source, how bright it appears as a function of frequency, usually follows a power law (because synchrotron radiation follows a power law). Let's plot the SED of the first source in the catalogue. We'll learn a few `pandas`, `numpy`, and `matplotlib` tricks along the way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "##Sort the data frame by how bright the sources are\n",
    "##(the column 'Fintwide'), with brightest first (so\n",
    "##we set ascending=False)\n",
    "df = df.sort_values('Fintwide',ascending=False)\n",
    "\n",
    "##Make an array of the known frequencies that we have data for\n",
    "freqs = np.array([76,84,92,99,107,115,122,130,143,151,158,166,174,181,189,197,204,212,220,227])\n",
    "\n",
    "##Convert the entire data set to a numpy array. We know \n",
    "##that the flux values are contiguous by frequency order,\n",
    "##so by converting to an array we can easily slice the \n",
    "##array to grab the data we care about\n",
    "df_as_array = df.to_numpy()\n",
    "\n",
    "##The original df contained both strings and float,\n",
    "##so this numpy array isn't strictly just floats\n",
    "##We wants floats to do maths to later, so do a\n",
    "##conversion below\n",
    "\n",
    "##When indexing a 2D array, the rows are indexed first,\n",
    "##columns second. We only want the flux columns here.\n",
    "##The : in the first index selects all rows\n",
    "##The second index 7:27 part is a slice, and returns from the 8th \n",
    "##column, all the way up to the 27th column, which are\n",
    "##the flux values (eg Fint076, Fint084, etc)\n",
    "spectrum_array = np.array(df_as_array[:,7:27],dtype=float)\n",
    "\n",
    "##Spectrum array now only has 20 columns of flux values\n",
    "##Select the first row to do some plotting with\n",
    "spectrum1 = spectrum_array[0,:]\n",
    "\n",
    "##Setup a figure and subplots, with one row\n",
    "##and two columns. This returns two Axes\n",
    "##objects in a list, that you can index and call\n",
    "fig, axs = plt.subplots(1,2)\n",
    "\n",
    "##Plot the data on the left axes\n",
    "axs[0].plot(freqs,spectrum1,'s',mfc='none')\n",
    "\n",
    "##Plot the data on a log-log plot\n",
    "axs[1].loglog(freqs,spectrum1,'s',mfc='none')\n",
    "\n",
    "##ALWAYS add axes labels so we know what we're\n",
    "##looking at:\n",
    "for ax in axs:\n",
    "    ax.set_xlabel('Freq (Hz)')\n",
    "    ax.set_ylabel('Flux density (Jy)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the two plots that a power law looks like a linear replationship when plotted on a log-log plot. This is because of the logarithm rules, which mean that $\\log(S_0\\nu^\\alpha) = \\log(S_0) + \\alpha log(\\nu)$.\n",
    "\n",
    "## <font color='blue'>Excercise 2.5<font>\n",
    "CHALLENGE TIME\n",
    "\n",
    "Let's use a technique we learned in the last notebook, and fit an SED!. For the first 100 brightest sources, fit a power-law to the spectrum using `lmfit`. You already have the array called `spectrum_array`, so you just need to loop over the first 100 sources in that. I've included the power-law model you need to import in the box below. Try googling \"lmfit PowerLawModel\" to find out what the variable names are (looking things up on the internet is your coding friend).\n",
    "    \n",
    "Once you've calculated 100 of your own spectral indexes, compare them to the original values in `df['alpha']`. Make plots to compare the catalogue numbers to your own. They should be similar, but they won't be the same. Can you figure out why? If you have enough compute power, trying calculating more than 100 SI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lmfit.models import PowerLawModel\n",
    "\n",
    "##YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
